{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Remove <keyword>Commercials</keyword> with <keyword>ffmpeg</keyword> and <keyword>PySceneDetect</keyword>\n",
    "*Managing non-contiguous sections*\n",
    "\n",
    "<created>01/11/2022</created>\n",
    "<updated>08/19/2022</updated>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Background\n",
    "\n",
    "I wanted to remove commercials from several hundred TV episodes present in a handful of recordings. Additionally, I wanted to split them per episode to be added to a media library.\n",
    "\n",
    "## Scene Detection\n",
    "\n",
    "Detecting the transition from content to commercial is made easy using [PySceneDetect](https://pyscenedetect.readthedocs.io/en/latest/).\n",
    "\n",
    "The default settings were nearly perfect at detecting the scene transition.\n",
    "\n",
    "### Usage\n",
    "\n",
    "PySceneDetect is easily called from the command line. However, as I was doing this in batches and wanted a way to incorporate reviewing the scenes and episode annotation with the conversion, I decided to use a Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen\n",
    "\n",
    "def get_scenes(folder, video):\n",
    "    args = [\"scenedetect\", \"-i\", video, \"detect-threshold\", \"list-scenes\", \"save-images\", \"export-html\", \"-w\",\n",
    "           \"320\", \"-h\", \"180\"]\n",
    "    with Popen(args, cwd=folder) as p:\n",
    "        p.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you see from the above function, PySceneDetect will generate a report of scenes detected, along with thumbnails to confirm their accuracy.\n",
    "\n",
    "With the report finished - I use some helper functions to work with the report and integrate it into Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Annotating Scenes\n",
    "\n",
    "To assign scenes to a video output, I came up with a simple syntax:\n",
    "\n",
    "```\n",
    "scene_stmt: number\n",
    "scene_range: number-number (inclusive)\n",
    "scene_break: number,number\n",
    "output_name: ...string\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "1. Select scenes 1-4 (inclusive), scene 7, and scenes 8-11 (inclusive) and save to a video named 'output'\n",
    "\n",
    "```python\n",
    "annotation = \"1-4,7,8-11...output\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Annotation Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_scene_annotation(s: str) -> list[list[tuple[int, int]], str]:\n",
    "    \"\"\"\n",
    "    Transform annotation to structured form\n",
    "    \"\"\"\n",
    "    scenes_str, output_name = s.split(\"...\")\n",
    "    scenes = []\n",
    "    for sc_range in scenes_str.split(\",\"):\n",
    "        # Split on disjointed scenes\n",
    "        sc_range = sc_range.strip()\n",
    "        if \"-\" not in sc_range:\n",
    "            # Single scene\n",
    "            scenes.append((int(sc_range), int(sc_range)))\n",
    "            continue\n",
    "        start, _, end = sc_range.partition(\"-\")\n",
    "        scenes.append((int(start.strip()), int(end.strip())))\n",
    "    return [scenes, output_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Translate Scene Numbers to Timestamps\n",
    "\n",
    "We will use the report from `PySceneDetect` to get translate scene numbers to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "scene_report_fp = Path(\"~/Videos/Captures/Scenes.csv\").expanduser()  # Scene Report\n",
    "df = pd.read_csv(scene_report_fp, skiprows=1, index_col=['Scene Number'])\n",
    "\n",
    "def get_scene_timestamp(scene_number: int, is_end: bool, df_scenes: pd.DataFrame) -> float:\n",
    "    \"\"\"Depending on if this scene_number starts a range or scene_ranges it return the appropriate timestamp\"\"\"\n",
    "    return df_scenes.at[scene_number, f\"{'End' if is_end else 'Start'} Time (seconds)\"]\n",
    "\n",
    "def get_scene_timestamps(ends, df_scenes: pd.DataFrame):\n",
    "    scene_times = []\n",
    "    for start, end in ends:\n",
    "        start_secs = get_scene_timestamp(start, is_end=False, df_scenes=df_scenes)\n",
    "        end_secs = get_scene_timestamp(start, is_end=True, df_scenes=df_scenes)\n",
    "        scene_times.append((start_secs, end_secs))\n",
    "    return scene_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build Filtergraph\n",
    "\n",
    "We convert scene numbers to timestamps and prepare them for ingestion with some ffmpeg specific logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def parse_scenes(scene_ranges: list[tuple[int, int]], df_scenes: pd.DataFrame, fast_seek_buffer: int = 100) -> tuple[\n",
    "    list[tuple[str, str]], str]:\n",
    "    \"\"\"\n",
    "    Fast seeking is not exact, so we want to start transcoding before the exact timestamp.\n",
    "    This requires recalculating our timestamps to adjust for the buffer.\n",
    "\n",
    "    Note that ffmpeg will discard the buffered portion, and will *not* be included in the output\n",
    "\n",
    "    We also want to convert our timestamps to strings, with .4f precision\n",
    "    \"\"\"\n",
    "\n",
    "    ends = get_scene_timestamps(scene_ranges, df_scenes=df_scenes)\n",
    "    \n",
    "    ss_start = min(chain.from_iterable(ends)) - fast_seek_buffer\n",
    "    ss_start = max([ss_start, 0])\n",
    "    new_pieces: list[tuple[str, str]] = []\n",
    "    for (start, end) in ends:\n",
    "        new_start = start - ss_start\n",
    "        new_end = end - ss_start\n",
    "        start_code = \"%.4f\" % new_start\n",
    "        end_code = \"%.4f\" % new_end\n",
    "        new_pieces.append((start_code, end_code))\n",
    "    ss_start_code = \"%.4f\" % ss_start\n",
    "    return new_pieces, ss_start_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hooking in ffmpeg\n",
    "\n",
    "<keyword>ffmpeg</keyword> can do this, but the <keyword>filtergraph</keyword> is very verbose!\n",
    "\n",
    "Fortunately, we can build this programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_filtergraph_pieces(scene_range: tuple[str, str], chunk: int):\n",
    "    \"\"\"\n",
    "    Trimming video and audio and setting the correcting the timestamp\n",
    "    \"\"\"\n",
    "    v = f\"[0:v]trim=start={scene_range[0]}:end={scene_range[1]},setpts=PTS-STARTPTS[{chunk}v];\"\n",
    "    a = f\"[0:a]atrim=start={scene_range[0]}:end={scene_range[1]},asetpts=PTS-STARTPTS[{chunk}a];\"\n",
    "    return v+a\n",
    "\n",
    "def make_concat_filtergraph(n_chunks: int):\n",
    "    \"\"\"\n",
    "    Rejoining the trim and atrim from above with concat\n",
    "    \"\"\"\n",
    "    pre = \"\"\n",
    "    for i in range(n_chunks):\n",
    "        pre += f\"[{i}v][{i}a]\"\n",
    "    pre_concat=f\"{pre}concat=n={n_chunks}:v=1:a=1[outv][outa]\"\n",
    "    return pre_concat\n",
    "\n",
    "def make_filtergraph(scene_ranges: list[tuple[str, str]]):\n",
    "    \"\"\"Generate the several lines of text for filtergraph\"\"\"\n",
    "    inputs = [make_filtergraph_pieces(scene_range=e, chunk=i) for i, e in enumerate(scene_ranges)]\n",
    "    inputs = \"\".join(inputs)\n",
    "    output_graph = make_concat_filtergraph(len(scene_ranges))\n",
    "    s =  inputs + output_graph\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example Outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Parsing Annotation\n",
    "```python\n",
    "command = \"1-3,7-23,25...myvid\"\n",
    "parsed = parse_scene_annotation(command)\n",
    "parsed\n",
    ">>> [(1, 3), (7, 23), (25, 25)], 'myvid']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Getting Timestamps\n",
    "\n",
    "```python\n",
    "ts = parsed_scenes(parsed[0], df)\n",
    "ts\n",
    ">>> ([('0.0000', '8.9170'), ('391.7830', '406.8830'), ('1001.5670', '1005.7000')], '0.0000')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Getting Filtergraph\n",
    "```python\n",
    "fg = make_filtergraph(ts)\n",
    "fg\n",
    ">>> '[0:v]trim=start=0.0000:end=8.9170,setpts=PTS-STARTPTS[0v];[0:a]atrim=start=0.0000:end=8.9170,asetpts=PTS-STARTPTS[0a];[0:v]trim=start=391.7830:end=406.8830,setpts=PTS-STARTPTS[1v];[0:a]atrim=start=391.7830:end=406.8830,asetpts=PTS-STARTPTS[1a];[0:v]trim=start=1001.5670:end=1005.7000,setpts=PTS-STARTPTS[2v];[0:a]atrim=start=1001.5670:end=1005.7000,asetpts=PTS-STARTPTS[2a];[0v][0a][1v][1a][2v][2a]concat=n=3:v=1:a=1[outv][outa]'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining It Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_command(command: str, src_video: str, video_format: str, output_folder: str, df_scenes: pd.DataFrame):\n",
    "    scene_ranges, name = parse_scene_annotation(command)\n",
    "    scene_ts, ss = parse_scenes(scene_ranges, df_scenes)\n",
    "    fg = make_filtergraph(scene_ts)\n",
    "    output_file = str((Path(output_folder).expanduser() / name).with_suffix(video_format))\n",
    "    \n",
    "    args = ['ffmpeg', '-i', src_video, '-filter_complex',\n",
    "           fg, \"-map\", \"[outv]\", \"-map\", \"[outa]\", \"-c:v\", \"h264\",\n",
    "            \"-preset\", \"slow\", \"-movflags\", \"+faststart\", \"-fps_mode\", \"passthrough\",\n",
    "           output_file]\n",
    "    return args\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen, STDOUT, PIPE\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "commands = [\n",
    "    \"1-3,7...myvid\",\n",
    "    \"13,16-22...my_over_vid\"\n",
    "]\n",
    "\n",
    "for command in tqdm(commands):\n",
    "    parsed_command = parse_command(command, src_video=\"/path/to/src.mp4\",\n",
    "                                   video_format=\".mp4\",\n",
    "                                   output_folder=\"/path/to/converted\",\n",
    "                                   df_scenes=df\n",
    "                                  )\n",
    "    with Popen(parsed_command) as p:\n",
    "        p.pcommunicate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
