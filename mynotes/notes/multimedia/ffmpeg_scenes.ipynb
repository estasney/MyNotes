{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Remove <keyword>Commercials</keyword> with <keyword>ffmpeg</keyword> and <keyword>PySceneDetect</keyword>\n",
    "*Managing non-contiguous sections*\n",
    "<created>01/11/2022</created>\n",
    "<updated></updated>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Background\n",
    "\n",
    "I wanted to remove commercials from several hundred TV episodes present in a handful of recordings. Additionally, I wanted to split them per episode to be added to a media library.\n",
    "\n",
    "## Scene Detection\n",
    "\n",
    "Detecting the transition from content to commercial is made easy using [PySceneDetect](https://pyscenedetect.readthedocs.io/en/latest/).\n",
    "\n",
    "The default settings were nearly perfect at detecting the scene transition.\n",
    "\n",
    "### Usage\n",
    "\n",
    "PySceneDetect is easily called from the command line. However, as I was doing this in batches and wanted a way to incorporate reviewing the scenes and episode annotation with the conversion, I decided to use a Jupyter Notebook\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from subprocess import Popen\n",
    "\n",
    "def get_scenes(folder, video):\n",
    "    args = [\"scenedetect\", \"-i\", video, \"detect-threshold\", \"list-scenes\", \"save-images\", \"export-html\", \"-w\",\n",
    "           \"320\", \"-h\", \"180\"]\n",
    "    with Popen(args, cwd=folder) as p:\n",
    "        p.communicate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you see from the above function, PySceneDetect will generate a report of scenes detected, along with thumbnails to confirm their accuracy.\n",
    "\n",
    "With the report finished - I used some helper functions to work with the report and integrate it into Jupyter."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from base64 import b64encode\n",
    "from IPython.display import display, HTML\n",
    "from io import BytesIO\n",
    "from itertools import chain\n",
    "\n",
    "video = \"~/Videos/movie.mkv\"\n",
    "scenes = glob(\"~/Videos/*.jpg\")  # Thumbnails from PySceneDetect\n",
    "scene_list = glob(\"~/Videos/Scenes.csv\")  # Scene Report\n",
    "\n",
    "def sort_scene(f):\n",
    "    \"\"\"Sort scenes by timecode\"\"\"\n",
    "    fp = Path(f).stem\n",
    "    scene_num, scene_idx = [int(x) for x in fp.split('-')[2:]]\n",
    "    return scene_num, scene_idx\n",
    "\n",
    "def get_scene_image(scene, imgs):\n",
    "    \"\"\"Given a scene, return it's thumbnail\"\"\"\n",
    "    matches = [img for img in imgs if sort_scene(img)[0] == scene]\n",
    "    matches.sort(key=sort_scene)\n",
    "    img_objs = [Image.open(f) for f in matches]\n",
    "    img_width = sum(i.width for i in img_objs)\n",
    "    img_height = max(i.height for i in img_objs)\n",
    "    scene_img = Image.new('RGB', (img_width, img_height))\n",
    "    x = 0\n",
    "    for i in img_objs:\n",
    "        scene_img.paste(i, (x, 0))\n",
    "        x += i.width\n",
    "    return scene_img\n",
    "\n",
    "def encode_b64_img(img):\n",
    "    \"\"\"Base64 encode thumbnail for display in Jupyter\"\"\"\n",
    "    fp = BytesIO()\n",
    "    img.save(fp, format='png')\n",
    "    b64_img = b64encode(fp.getvalue()).decode('ascii')\n",
    "    return f\"data:image/png;base64,{b64_img}\"\n",
    "\n",
    "def embed_scene_image(scene, imgs, df):\n",
    "    \"\"\"Given a scene, retrieve its thumbnail and display it's timestamps\"\"\"\n",
    "    img = get_scene_image(scene, imgs=imgs)\n",
    "    img_b64 = encode_b64_img(img)\n",
    "    scene_data = df.loc[df['Scene Number'] == scene]\n",
    "    scene_start = scene_data.iat[0, 3]\n",
    "    scene_end = scene_data.iat[0, 6]\n",
    "    scene_length = scene_data.iat[0, 9]\n",
    "    element = HTML(f'''<div>\n",
    "    <h2>Scene: {scene}</h2>\n",
    "    <h3>{scene_start} - {scene_end} ({scene_length})</h3>\n",
    "    <img src=\"{img_b64}\"/></div>''')\n",
    "    display(element)\n",
    "\n",
    "def parse_scene(scene, is_end, df):\n",
    "    scene_data = df.loc[df['Scene Number'] == scene]\n",
    "    scene_start = scene_data.iat[0, 3]\n",
    "    scene_end = scene_data.iat[0, 6]\n",
    "    scene_length = scene_data.iat[0, 9]\n",
    "    if is_end:\n",
    "        return scene_end\n",
    "    return scene_start\n",
    "\n",
    "def parse_scenes(ends, df):\n",
    "    scene_times = []\n",
    "    for start, end in ends:\n",
    "        start_secs = parse_scene(start, False, df)\n",
    "        end_secs = parse_scene(end, True, df)\n",
    "        scene_times.append((start_secs, end_secs))\n",
    "    return scene_times\n",
    "\n",
    "def parse_ss(ends, df, as_scenes=True):\n",
    "    if as_scenes:\n",
    "        ends = parse_scenes(ends, df)\n",
    "    ss_start = min(chain.from_iterable(ends)) - 100\n",
    "    ss_start = max([ss_start, 0])\n",
    "    new_pieces = []\n",
    "    for (start, end) in ends:\n",
    "        new_start = start - ss_start\n",
    "        new_end = end - ss_start\n",
    "        new_pieces.append((f\"{new_start:.04f}\", f\"{new_end:.04f}\"))\n",
    "    return new_pieces, f\"{ss_start:.04f}\"\n",
    "\n",
    "def parse_scene_annotation(s):\n",
    "    try:\n",
    "        scenes_str, output = s.split(\"...\")\n",
    "        if not output.endswith(\".mp4\"):\n",
    "            output = f\"{output}.mp4\"\n",
    "        scenes = []\n",
    "        for sc in scenes_str.split(\",\"):\n",
    "            sc = sc.strip()\n",
    "            if \"-\" not in sc:\n",
    "                scenes.append((int(sc), int(sc)))\n",
    "                continue\n",
    "            start, end = [x.strip() for x in sc.split(\"-\")]\n",
    "            scenes.append((int(start), int(end)))\n",
    "\n",
    "        return [scenes, output]\n",
    "    except Exception as e:\n",
    "        print(s, e)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There's a lot of \"plumbing code\" going on above. But it serves to allow me to write the instructions like:\n",
    "\n",
    "```python\n",
    "episodes = [\n",
    "     \"2-3,10-11...S06E36\",\n",
    "    ]\n",
    "```\n",
    "\n",
    "Which is interpreted as:\n",
    "\"2-3,10-11\"  -> Select Scenes 2, 3, 10, 11 and Output as S06E36.mp4\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hooking in ffmpeg\n",
    "\n",
    "<keyword>ffmpeg</keyword> can do this, but the filtergraph is... very verbose!\n",
    "\n",
    "Below is some additional plumbing code that writes this out based on the scene and episode command"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_filtergraph_pieces(ends, n):\n",
    "    \"\"\"Trimming video and audio and setting the timestamp\"\"\"\n",
    "    v = f\"[0:v]trim=start={ends[0]}:end={ends[1]},setpts=PTS-STARTPTS[{n}v];\"\n",
    "    a = f\"[0:a]atrim=start={ends[0]}:end={ends[1]},asetpts=PTS-STARTPTS[{n}a];\"\n",
    "    return v+a\n",
    "\n",
    "def make_concat_filtergraph(n):\n",
    "    \"\"\"Rejoining the trim and atrim from above with concat\"\"\"\n",
    "    pre = \"\"\n",
    "    for i in range(n):\n",
    "        pre += f\"[{i}v][{i}a]\"\n",
    "    pre_concat=f\"{pre}concat=n={n}:v=1:a=1[outv][outa]\"\n",
    "    return pre_concat\n",
    "\n",
    "def make_filtergraph(ends):\n",
    "    \"\"\"Generate the several lines of text for filtergraph\"\"\"\n",
    "    n = len(ends)\n",
    "    inputs = [make_filtergraph_pieces(e, i) for i, e in enumerate(ends)]\n",
    "    inputs = \"\".join(inputs)\n",
    "    output_graph = make_concat_filtergraph(n)\n",
    "    s =  inputs + output_graph\n",
    "    return s\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ready"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from subprocess import Popen, STDOUT, PIPE\n",
    "\n",
    "episode_commands = parse_scene_annotation(episodes)\n",
    "\n",
    "def extract_pieces(pieces, input_file, output_file):\n",
    "    \"\"\"Uses cuda h264. This can be swapped out as needed\"\"\"\n",
    "    pieces = parse_scenes(pieces, df)\n",
    "\n",
    "    args = ['ffmpeg', '-vsync', '0', '-hwaccel', 'cuda', '-i', input_file, '-filter_complex',\n",
    "           make_filtergraph(pieces), \"-map\", \"[outv]\", \"-map\", \"[outa]\", \"-c:v\", \"h264_nvenc\", \"-preset\", \"slow\", \"-movflags\", \"+faststart\",\n",
    "           output_file]\n",
    "\n",
    "    with Popen(args) as p:\n",
    "        p.communicate()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(scene_list, skiprows=1)\n",
    "df['Start Timecode'] = pd.to_timedelta(df['Start Timecode'])\n",
    "df['End Timecode'] = pd.to_timedelta(df['End Timecode'])\n",
    "\n",
    "\n",
    "for scenes, out in tqdm(episode_commands):\n",
    "    mv_out = os.path.join(\"~/Videos/Episodes\", out)\n",
    "    extract_pieces(scenes, video, mv_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}